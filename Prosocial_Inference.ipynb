{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Minimal code for inverting a utility function\n",
    "import numpy as np\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "#### PROSOCIAL INFERENCE ####\n",
    "#############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Add features to the social environment ('Event')\n",
    "\n",
    "class Event:\n",
    "    def __init__(self, options, agentvalue, agentbeliefs, recipientvalue, choicespace, choice, outcome): # 'self' allows function to call itself\n",
    "        self.options = options # unique resources a prosocial agent can share \n",
    "        self.agentvalue = agentvalue # the value the prosocial agent places on the resources being shared\n",
    "        self.agentbeliefs = agentbeliefs # agents beliefs (certainty) about what the recipient values\n",
    "        self.recipientvalue = recipientvalue # the value the recipient places on the resources (i.e., their needs)\n",
    "        self.choicespace = choicespace # all possible prosocial choices\n",
    "        self.choice = choice # the prosocial agent's choice\n",
    "        self.outcome = outcome # prosocial agent's benefits from acting (e.g, praise, good feelings)\n",
    "        \n",
    "#additions\n",
    "    #social norms (action is normative (common) vs supra-normative)\n",
    "    #reward expectations (expects to benefit or does not)\n",
    "    #reward outcomes (benefits or does not)\n",
    "    #reactions (happy or not happy)\n",
    "    \n",
    "    \n",
    "    # ToM should be called within a model of morality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define features of our specific prosocial scenario\n",
    "\n",
    "nice = Event(['a','b'], # options (unique actions)\n",
    "                  [1,1], # agentvalue (agent's value on actions)\n",
    "                  [[1,0],[0,1],[.5,.5]], # agentbeliefs (agent's beliefs (certainty) about recipient's value for each action)\n",
    "                  [10,0], # recipientvalue (recipient's value on unique actions)\n",
    "                  [['a','a'], # choicespace (possible actions) \n",
    "                   ['b','b'],\n",
    "                   ['a','b'],\n",
    "                  ['a','a','a','a'],\n",
    "                  ['b','b','b','b'],\n",
    "                  ['a','b','a','b']],\n",
    "                  2, # choice in choicespace (action)\n",
    "             1 # outcomes of choice (benefitted? y[1]/n[0])\n",
    "            ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "niceness(Sacrifice model): 0.5\n",
      "niceness(Other-utility model): 0.25\n",
      "niceness(Purity model): 1\n"
     ]
    }
   ],
   "source": [
    "### SACRIFICE MODEL ###\n",
    "\n",
    "    ## Do some basic division\n",
    "\n",
    "sacr_outcome = len(nice.choicespace[nice.choice]) \\\n",
    "/len(max(nice.choicespace,key=len))\n",
    "\n",
    "\n",
    "print(\"niceness(Sacrifice model):\", sacr_outcome)\n",
    "\n",
    "## Other possible models (sacrifice relative to norm, or observed actions when repeated observation possible)\n",
    "\n",
    "\n",
    "### OTHER-UTILITY MODEL ###\n",
    "\n",
    "    ## Dictionary to convert unique actions into recipient utilities\n",
    "\n",
    "utility = {\n",
    "    nice.options[0]: nice.recipientvalue[0], # action 1 -> recipient utility 1\n",
    "    nice.options[1]: nice.recipientvalue[1] # action 2 -> recipient utility 2\n",
    "}\n",
    "\n",
    "    ## Get choice utilities via list comprehension\n",
    "u = []\n",
    "for choice in range(len(nice.choicespace)):\n",
    "    u.append(sum([utility[m] for m in nice.choicespace[choice]]))\n",
    "    \n",
    "util_outcome= abs(u[nice.choice]/max(u)) #Choice utility divided by max possibile choice utility\n",
    "\n",
    "\n",
    "print(\"niceness(Other-utility model):\", util_outcome)\n",
    "\n",
    "\n",
    "### PURITY MODEL ###\n",
    "\n",
    "    ## If the agent acted nice without benefitting, act was pure\n",
    "if len(nice.choicespace[nice.choice]) > 0:\n",
    "    pure_outcome=((len(nice.choicespace[nice.choice])*1) - nice.outcome)\n",
    "else:\n",
    "    pure_outcome=0\n",
    "print(\"niceness(Purity model):\", pure_outcome)\n",
    "\n",
    "\n",
    "### HYBRID MODEL ###\n",
    "\n",
    "#need to decide weights\n",
    "\n",
    "\n",
    "### ToM MODEL ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### ToM MODEL\n",
    "\n",
    "#define an agent, just an event\n",
    "    #how much agent values each object [5,0]\n",
    "    #how much agent value giving any object [1,1]\n",
    "    #caring about others = 0-1\n",
    "    \n",
    "#where giving [a,a] would mean =  x\n",
    "# they chose  choice 2 out of 3.\n",
    "# simulate agents and see which agent would be maximizing \n",
    "# giving two 2, means don't care about value of a, or they care alot o\n",
    "\n",
    "# how much they value objects and how much they care about person are unknown\n",
    "\n",
    "# value of giving all objects should be equal\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "#GOALS\n",
    "# finish agent who knows others' rewards\n",
    "# loop through everything that can vary, nested for loops\n",
    "# get predictions for each\n",
    "# look in R\n",
    "# some dimensions matter, some are interesting\n",
    "\n",
    "\n",
    "# norms (simulating past observation of people, knowledge, \n",
    "#get norms by asking people who much they expect people to give from turk, input that into the \n",
    "#model\n",
    "#- moral judgments \n",
    "#what people tell you the norms are, plug in to the model\n",
    "#or set parameter, and try to fit that parameter to look like  \n",
    "#\n",
    "#try to figoure out the norm, based on niceeness judgment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
